{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53f0cb29-b0c8-4a5f-96e1-70d919e8704a",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.015731,
     "end_time": "2024-08-01T22:26:39.009133",
     "exception": false,
     "start_time": "2024-08-01T22:26:38.993402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Project Objective:**\n",
    "\n",
    "In this project, we forecast sales for the next 3 months for 50 different products across 10 different stores using 5 years of store-item sales data. The dataset includes daily sales figures for each store and product. We've applied various techniques to analyze this time series data and predict future demand using machine learning methods.\n",
    "\n",
    "**Key Highlights:**\n",
    "\n",
    "- **Model Utilization:** Employed the LightGBM algorithm for sales forecasting. LightGBM is effective in handling large datasets and provides high accuracy.\n",
    "  \n",
    "- **Time Series Features:** To enhance model accuracy, we created several key date features:\n",
    "  - **Exponentially Weighted Mean (EWM):** I computed the exponentially weighted mean on sales data. This method gives more weight to recent data, making the model more sensitive to recent changes and improving prediction accuracy.\n",
    "  - **Rolling Mean:** I calculated rolling mean to better model trends and seasonality effects.\n",
    "  - **Lag Features:** I created lag features using past sales data to incorporate historical performance into the model.\n",
    "  \n",
    "- **Time Series Analysis:** We processed time series data by considering seasonal patterns, trends, and cyclical effects.\n",
    "\n",
    "In this project, we achieved high accuracy in sales predictions by applying techniques such as EWM, rolling mean, and lag features to time series data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b064134d-efe9-4adc-84e8-700f3b253530",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:39.037301Z",
     "iopub.status.busy": "2024-08-01T22:26:39.036870Z",
     "iopub.status.idle": "2024-08-01T22:26:43.632860Z",
     "shell.execute_reply": "2024-08-01T22:26:43.631583Z"
    },
    "papermill": {
     "duration": 4.613486,
     "end_time": "2024-08-01T22:26:43.635907",
     "exception": false,
     "start_time": "2024-08-01T22:26:39.022421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from tabulate import tabulate\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "import sys\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c128ee20-1649-4773-969b-50aca0fed359",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "This script aims to define custom exception for exception handling purposes. It will be easier to identify errors and issues.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Importing the libraries.\n",
    "'''\n",
    "\n",
    "# Debugging and verbose.\n",
    "import sys\n",
    "\n",
    "\n",
    "def detailed_error_msg(error, error_details: sys):\n",
    "    '''\n",
    "    Generate a detailed error message including file name, line number, and error message.\n",
    "    \n",
    "    Args:\n",
    "        error: The original error or exception.\n",
    "        error_details (sys): System information about the error.\n",
    "        \n",
    "    Returns:\n",
    "        str: A detailed error message.\n",
    "    '''\n",
    "    _, _, exception_traceback = error_details.exc_info()\n",
    "    file_name = exception_traceback.tb_frame.f_code.co_filename\n",
    "    line_number = exception_traceback.tb_lineno\n",
    "    detailed_error_message = f'An error occurred in python file [{file_name}] line number [{line_number}] error message [{str(error)}]'\n",
    "    \n",
    "    return detailed_error_message\n",
    "\n",
    "\n",
    "class CustomException(Exception):\n",
    "    '''\n",
    "    Custom exception class with detailed error information.\n",
    "    '''\n",
    "    def __init__(self, detailed_error_message: str, error_details: sys) -> None:\n",
    "        '''\n",
    "        Initialize a DetailedException instance.\n",
    "\n",
    "        Args:\n",
    "            detailed_error_message (str): The detailed error message.\n",
    "            error_details (sys): System information about the error.\n",
    "        '''\n",
    "        super().__init__(detailed_error_message)\n",
    "        self.detailed_error_message = detailed_error_msg(detailed_error_message, error_details=error_details)\n",
    "\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        '''\n",
    "        Convert the exception to a string representation.\n",
    "        \n",
    "        Returns:\n",
    "            str: The detailed error message.\n",
    "        '''\n",
    "        return self.detailed_error_message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff60df52-20b4-4ff1-9715-682951728465",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_time_series_features(data, target, to_sort=None, to_group=None, lags=None, windows=None, weights=None, min_periods=None, win_type=None, date_related=True, lag=False, log_transformation=False, roll=False, ewm=False, roll_mean=False, roll_std=False, roll_min=False, roll_max=False):\n",
    "    '''\n",
    "    Create time-series features from the given data.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): The input data containing time-series information.\n",
    "        target (str): The name of the target variable.\n",
    "        to_sort (str, optional): The column name used for sorting the data. Defaults to None.\n",
    "        to_group (str, optional): The column name used for grouping data. Defaults to None.\n",
    "        lags (list of int, optional): List of lag values for creating lag features. Defaults to None.\n",
    "        windows (list of int, optional): List of window sizes for creating rolling window features. Defaults to None.\n",
    "        weights (list of float, optional): List of weights for creating exponentially weighted mean features. Defaults to None.\n",
    "        min_periods (int, optional): The minimum number of observations required to have a value. Defaults to None.\n",
    "        win_type (str, optional): The window type for rolling window calculations. Defaults to None.\n",
    "        date_related (bool, optional): Flag indicating whether to create date-related features. Defaults to True.\n",
    "        lag (bool, optional): Flag indicating whether to create lag features. Defaults to False.\n",
    "        log_transformation (bool, optional): Flag indicating whether to apply log transformation to the target variable. Defaults to False.\n",
    "        roll (bool, optional): Flag indicating whether to create rolling window features. Defaults to False.\n",
    "        ewm (bool, optional): Flag indicating whether to create exponentially weighted mean features. Defaults to False.\n",
    "        roll_mean (bool, optional): Flag indicating whether to create rolling mean features. Defaults to False.\n",
    "        roll_std (bool, optional): Flag indicating whether to create rolling standard deviation features. Defaults to False.\n",
    "        roll_min (bool, optional): Flag indicating whether to create rolling minimum features. Defaults to False.\n",
    "        roll_max (bool, optional): Flag indicating whether to create rolling maximum features. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the original data with additional time-series features.\n",
    "\n",
    "    Raises:\n",
    "        CustomException: If an exception occurs during feature creation.\n",
    "    '''\n",
    "    try:\n",
    "        df = data.copy()\n",
    "\n",
    "        # Create date-related features.\n",
    "        if date_related:\n",
    "            df['dayofweek'] = df.index.dayofweek\n",
    "            df['quarter'] = df.index.quarter\n",
    "            df['month'] = df.index.month\n",
    "            df['year'] = df.index.year\n",
    "            df['dayofyear'] = df.index.dayofyear\n",
    "            df['dayofmonth'] = df.index.day\n",
    "            df['weekofyear'] = df.index.isocalendar().week.astype(np.float64)\n",
    "            df['is_wknd'] = df.index.weekday // 4\n",
    "            df['is_month_start'] = df.index.is_month_start.astype(int)\n",
    "            df['is_month_end'] = df.index.is_month_end.astype(int)\n",
    "\n",
    "        # Apply log_transformation to the target variable.\n",
    "        if log_transformation:\n",
    "            df[target] = np.log1p(df[target])\n",
    "        \n",
    "        # Create lag features.\n",
    "        if lag:\n",
    "            df.sort_values(by=to_sort, axis=0, inplace=True)\n",
    "            for lag in lags:\n",
    "                df['sales_lag_' + str(lag)] = df.groupby(to_group)[target].transform(lambda x: x.shift(lag))\n",
    "        \n",
    "        # Create rolling window features.\n",
    "        if roll:\n",
    "            df.sort_values(by=to_sort, axis=0, inplace=True)\n",
    "\n",
    "            if roll_mean:\n",
    "                for window in windows:\n",
    "                    df['sales_roll_mean_' + str(window)] = df.groupby(to_group)[target].transform(lambda x: x.shift(1).rolling(window=window, min_periods=min_periods, win_type=win_type).mean())\n",
    "            if roll_std:\n",
    "                for window in windows:\n",
    "                    df['sales_roll_std_' + str(window)] = df.groupby(to_group)[target].transform(lambda x: x.shift(1).rolling(window=window, min_periods=min_periods, win_type=win_type).std())\n",
    "            if roll_min:\n",
    "                for window in windows:\n",
    "                    df['sales_roll_min_' + str(window)] = df.groupby(to_group)[target].transform(lambda x: x.shift(1).rolling(window=window, min_periods=min_periods, win_type=win_type).min())\n",
    "            if roll_max:\n",
    "                for window in windows:\n",
    "                    df['sales_roll_max_' + str(window)] = df.groupby(to_group)[target].transform(lambda x: x.shift(1).rolling(window=window, min_periods=min_periods, win_type=win_type).max())\n",
    "\n",
    "        # Create exponentially weighted mean features.\n",
    "        if ewm:\n",
    "            for weight in weights:\n",
    "                    for lag in lags:\n",
    "                        df['sales_ewm_w_' + str(weight) + '_lag_' + str(lag)] = df.groupby(to_group)[target].transform(lambda x: x.shift(lag).ewm(alpha=weight).mean())\n",
    "            \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)\n",
    "\n",
    "def time_series_split(data, cutoff_date):\n",
    "    '''\n",
    "    Splits the time series data into train and test sets on a chronological order based on the cutoff date.\n",
    "\n",
    "    Args:\n",
    "    data (pandas.DataFrame): The time series data to be split.\n",
    "    cutoff_date (str or datetime): The date that separates the training and test sets.\n",
    "\n",
    "    Raises:\n",
    "    CustomException: An error occurred during the time series split.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two pandas.DataFrame objects, where the first one represents the training set\n",
    "    with data before the cutoff date, and the second one represents the test set with data on and after the cutoff date.\n",
    "    '''\n",
    "    try:\n",
    "        train = data.loc[data.index < cutoff_date]\n",
    "        test = data.loc[data.index >= cutoff_date]\n",
    "        return train, test\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)\n",
    "    \n",
    "\n",
    "def plot_time_series_split(train, test, cutoff_date):\n",
    "    '''\n",
    "    Plots the time series data after splitting into train and test sets.\n",
    "\n",
    "    Args:\n",
    "    train (pandas.DataFrame): The training data to be plotted.\n",
    "    test (pandas.DataFrame): The test data to be plotted.\n",
    "    cutoff_date (str or datetime): The date that separates the training and test sets.\n",
    "\n",
    "    Raises:\n",
    "    CustomException: An error occurred during the plotting process.\n",
    "    '''\n",
    "    try:\n",
    "        figure, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "        train.plot(ax=ax, label='Train', y='sales')\n",
    "        test.plot(ax=ax, label='Test', y='sales')\n",
    "\n",
    "        ax.axvline(cutoff_date, color='black', ls='--')\n",
    "\n",
    "        plt.title('Time series train-test-split', fontsize=25, fontweight='bold', loc='left', pad=25)\n",
    "        plt.xlabel('Date', loc='left', labelpad=25)\n",
    "        plt.ylabel('Sales', loc='top', labelpad=25)\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0465da8c-b56e-43e9-ae02-c399bea2954d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#SET GLOBAL FLAG\n",
    "should_continue_execution = True  # Default to True\n",
    "\n",
    "# Utils.\n",
    "#from src.modelling_utils import create_time_series_features, time_series_split, plot_time_series_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea9657f0-7be1-497a-8710-583ec3b7c72c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Sending Message: {&#34;progress&#34;: &#34;20&#34;, &#34;id&#34;: 9, &#34;name&#34;: &#34;Progress&#34;, &#34;title&#34;: &#34;Progress&#34;, &#34;type&#34;: &#34;progress&#34;, &#34;resultType&#34;: 3, &#34;visibility&#34;: &#34;EXPANDED&#34;, &#34;time&#34;: &#34;Oct 10, 2024 05:34:54 PM&#34;}\n",
       "Not sending message to fire_notebook server as the post back URL is not http\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Sending Message: {&#34;progress&#34;: &#34;20&#34;, &#34;id&#34;: 9, &#34;name&#34;: &#34;Progress&#34;, &#34;title&#34;: &#34;Progress&#34;, &#34;type&#34;: &#34;progress&#34;, &#34;resultType&#34;: 3, &#34;visibility&#34;: &#34;EXPANDED&#34;, &#34;time&#34;: &#34;Oct 10, 2024 05:34:54 PM&#34;}\nNot sending message to fire_notebook server as the post back URL is not http\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Widgets used to pass value\n",
    "dbutils.widgets.text(\"job-id\", \"100\")\n",
    "dbutils.widgets.text(\"postback-url\", \"\")\n",
    "dbutils.widgets.text(\"rb_detail\", \"\")\n",
    "dbutils.widgets.text(\"rb_summary\", \"\")\n",
    "dbutils.widgets.text(\"rb_detail_org\", \"\")\n",
    "\n",
    "#dbutils.widgets.text(\"bt_insights\", \"N\")\n",
    "\n",
    "jobId = dbutils.widgets.get(\"job-id\")\n",
    "rb_detail = dbutils.widgets.get(\"rb_detail\")\n",
    "rb_features = dbutils.widgets.get(\"rb_detail\")\n",
    "rb_detail_org = dbutils.widgets.get(\"rb_detail_org\")\n",
    "if rb_detail_org == '3':\n",
    "    rb_detail = '3'\n",
    "rb_summary = dbutils.widgets.get(\"rb_summary\")\n",
    "webserverURL = dbutils.widgets.get(\"postback-url\")\n",
    "bt_insights = rb_detail\n",
    "#print(f\"parameter_value for key rb_summary is: {rb_summary} and parameter_value for key rb_detail is: {rb_detail}\")\n",
    "#print(f\"parameter_value for key rb_features is: {rb_features}\")\n",
    "#Initialize and Start Execution\n",
    "from fire_notebook.output.workflowcontext import RestWorkflowContext\n",
    "restworkflowcontext = RestWorkflowContext(webserverURL, jobId)\n",
    "message=\"20\"\n",
    "restworkflowcontext.outputProgress(9, title=\"Progress\", progress=message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "686a4f8b-9308-4e6d-80c8-e3af03434fc2",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.013106,
     "end_time": "2024-08-01T22:26:43.662284",
     "exception": false,
     "start_time": "2024-08-01T22:26:43.649178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### EDA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61e3d8e6-e40c-4213-b43c-045fef96ef8b",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:43.692849Z",
     "iopub.status.busy": "2024-08-01T22:26:43.691613Z",
     "iopub.status.idle": "2024-08-01T22:26:43.707174Z",
     "shell.execute_reply": "2024-08-01T22:26:43.705841Z"
    },
    "papermill": {
     "duration": 0.034559,
     "end_time": "2024-08-01T22:26:43.709852",
     "exception": false,
     "start_time": "2024-08-01T22:26:43.675293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the check_df function\n",
    "def check_df(dataframe: pd.DataFrame, head: int = 5) -> None:\n",
    "    # Print DataFrame shape\n",
    "    htmlstr1 = f\"\"\"\n",
    "    <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "        <h3>DataFrame Shape</h3>\n",
    "        <p>Rows: {dataframe.shape[0]}, Columns: {dataframe.shape[1]}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    restworkflowcontext.outHTML(9, title=\"DataFrame Shape\", text=htmlstr1)\n",
    "\n",
    "    # Print DataFrame unique values in HTML format\n",
    "    unique_values = dataframe.nunique().reset_index()\n",
    "    unique_values.columns = ['Column', 'Unique Values']\n",
    "    unique_values_html = unique_values.to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "\n",
    "    # Extract only the <tbody> section from the generated HTML\n",
    "    tbody_start = unique_values_html.find('<tbody>')\n",
    "    tbody_end = unique_values_html.find('</tbody>') + len('</tbody>')\n",
    "    unique_values_tbody = unique_values_html[tbody_start:tbody_end]\n",
    "\n",
    "    unique_values_html_full = f\"\"\"\n",
    "    <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "        <table class=\"table table-striped\" id=\"unique_values_table\" style=\"width: 100%; text-align: left;\">\n",
    "            <thead style=\"text-align: left;\">\n",
    "                <tr>\n",
    "                    <th>Column</th>\n",
    "                    <th>Unique Values</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            {unique_values_tbody}\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    restworkflowcontext.outHTML(10, title=\"Unique Values Per Column\", text=unique_values_html_full)\n",
    "\n",
    "    # Print DataFrame data types\n",
    "    data_types = dataframe.dtypes.reset_index()\n",
    "    data_types.columns = ['Column', 'Data Type']\n",
    "    data_types_html = data_types.to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "    # Extract only the <tbody> section from the generated HTML\n",
    "    tbody_start = data_types_html.find('<tbody>')\n",
    "    tbody_end = data_types_html.find('</tbody>') + len('</tbody>')\n",
    "    data_types_tbody = data_types_html[tbody_start:tbody_end]\n",
    "\n",
    "    data_types_html_full = f\"\"\"\n",
    "    <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "        <table class=\"table table-striped\" id=\"data_types_table\" style=\"width: 100%; text-align: left;\">\n",
    "            <thead style=\"text-align: left;\">\n",
    "                <tr>\n",
    "                    <th>Column</th>\n",
    "                    <th>Data Type</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            {data_types_tbody}\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    restworkflowcontext.outHTML(11, title=\"Data Types\", text=data_types_html_full)\n",
    "\n",
    "    # Print head of the DataFrame\n",
    "    head_html = dataframe.head().to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "    # Extract only the <tbody> section from the generated HTML\n",
    "    tbody_start = head_html.find('<tbody>')\n",
    "    tbody_end = head_html.find('</tbody>') + len('</tbody>')\n",
    "    head_tbody = head_html[tbody_start:tbody_end]\n",
    "\n",
    "    head_html_full = f\"\"\"\n",
    "    <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "        <table class=\"table table-striped\" id=\"head_table\" style=\"width: 100%; text-align: left;\">\n",
    "            <thead style=\"text-align: left;\">\n",
    "                <tr>\n",
    "                    {\"\".join(f\"<th>{col}</th>\" for col in dataframe.columns)}\n",
    "                </tr>\n",
    "            </thead>\n",
    "            {head_tbody}\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    restworkflowcontext.outHTML(12, title=\"Top Rows (Head)\", text=head_html_full)\n",
    "\n",
    "    # Print tail of the DataFrame\n",
    "    tail_html = dataframe.tail().to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "    # Extract only the <tbody> section from the generated HTML\n",
    "    tbody_start = tail_html.find('<tbody>')\n",
    "    tbody_end = tail_html.find('</tbody>') + len('</tbody>')\n",
    "    tail_tbody = tail_html[tbody_start:tbody_end]\n",
    "\n",
    "    tail_html_full = f\"\"\"\n",
    "    <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "        <table class=\"table table-striped\" id=\"tail_table\" style=\"width: 100%; text-align: left;\">\n",
    "            <thead style=\"text-align: left;\">\n",
    "                <tr>\n",
    "                    {\"\".join(f\"<th>{col}</th>\" for col in dataframe.columns)}\n",
    "                </tr>\n",
    "            </thead>\n",
    "            {tail_tbody}\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    restworkflowcontext.outHTML(13, title=\"Bottom Rows (Tail)\", text=tail_html_full)    \n",
    "\n",
    "    # Print missing values\n",
    "    missing_values = dataframe.isnull().sum().reset_index()\n",
    "    missing_values.columns = ['Column', 'Missing Values']\n",
    "    missing_values_html = missing_values.to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "# Extract only the <tbody> section from the generated HTML\n",
    "    tbody_start = missing_values_html.find('<tbody>')\n",
    "    tbody_end = missing_values_html.find('</tbody>') + len('</tbody>')\n",
    "    missing_values_tbody = missing_values_html[tbody_start:tbody_end]\n",
    "\n",
    "    missing_values_html_full = f\"\"\"\n",
    "    <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "        <table class=\"table table-striped\" id=\"missing_values_table\" style=\"width: 100%; text-align: left;\">\n",
    "            <thead style=\"text-align: left;\">\n",
    "                <tr>\n",
    "                    <th>Column</th>\n",
    "                    <th>Missing Values</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            {missing_values_tbody}\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    restworkflowcontext.outHTML(14, title=\"Missing Values Per Column\", text=missing_values_html_full)\n",
    "\n",
    "    # Print date range if 'date' column exists\n",
    "    if 'date' in dataframe.columns and pd.api.types.is_datetime64_any_dtype(dataframe['date']):\n",
    "        date_range_html = f\"\"\"\n",
    "        <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "            <h3>Date Range</h3>\n",
    "            <p>Start Date: {dataframe['date'].min()}</p>\n",
    "            <p>End Date: {dataframe['date'].max()}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        restworkflowcontext.outHTML(15, title=\"Date Range\", text=date_range_html)\n",
    "\n",
    "    # Print quantile statistics\n",
    "    quantiles = dataframe.describe([0, 0.05, 0.50, 0.95, 0.99, 1]).T.reset_index()\n",
    "    quantiles_html = quantiles.to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "    # Extract only the <tbody> section from the generated HTML\n",
    "    tbody_start = quantiles_html.find('<tbody>')\n",
    "    tbody_end = quantiles_html.find('</tbody>') + len('</tbody>')\n",
    "    quantiles_tbody = quantiles_html[tbody_start:tbody_end]\n",
    "\n",
    "    quantiles_html_full = f\"\"\"\n",
    "    <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "        <table class=\"table table-striped\" id=\"quantiles_table\" style=\"width: 100%; text-align: left;\">\n",
    "            <thead style=\"text-align: left;\">\n",
    "                <tr>\n",
    "                    {\"\".join(f\"<th>{col}</th>\" for col in quantiles.columns)}\n",
    "                </tr>\n",
    "            </thead>\n",
    "            {quantiles_tbody}\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    restworkflowcontext.outHTML(16, title=\"Quantiles\", text=quantiles_html_full)\n",
    "\n",
    "\n",
    "# target summary with cat cols\n",
    "# Function to see the average sales for each store and the average sales for each item.\n",
    "#Example Business Questions that can be answered:\n",
    "    #Which store has the highest average sales value?\n",
    "    #Which item has the lowest average sales value?\n",
    "\n",
    "def target_summary_with_cat(dataframe, target, categorical_cols):\n",
    "    for col in categorical_cols:\n",
    "        summary_df = dataframe.groupby(col)[target].mean().reset_index()\n",
    "        summary_df.columns = [col, \"TARGET_MEAN\"]\n",
    "\n",
    "        # Convert DataFrame to HTML\n",
    "        summary_html = summary_df.to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "        # Extract <tbody> section (optional, for styling)\n",
    "        tbody_start = summary_html.find('<tbody>')\n",
    "        tbody_end = summary_html.find('</tbody>') + len('</tbody>')\n",
    "        summary_tbody = summary_html[tbody_start:tbody_end]\n",
    "\n",
    "        # Wrap HTML in a div for styling (optional)\n",
    "        summary_html_full = f\"\"\"\n",
    "        <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 10px; background-color: #f9f9f9;\">\n",
    "            <table class=\"table table-striped\" id=\"summary_table\" style=\"width: 100%; text-align: left;\">\n",
    "                <thead>\n",
    "                    <tr>\n",
    "                        <th>{col}</th>\n",
    "                        <th>TARGET_MEAN</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                {summary_tbody}\n",
    "            </table>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        restworkflowcontext.outHTML(16, title=\"Detailed Report\", text=summary_html_full)\n",
    "\n",
    "        print(summary_df, end=\"\\n\\n\\n\")\n",
    "\n",
    "        # Create histogram\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.bar(summary_df[col].astype(str), summary_df[\"TARGET_MEAN\"], color='skyblue')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(target)\n",
    "        plt.title(f\"{target} mean for {col}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "        #fig = plotly.offline.plot([go.Bar(x=summary_df[col], y=summary_df[\"TARGET_MEAN\"])], output_type='div', include_plotlyjs=False)\n",
    "        #example_plotly = f'{fig}'\n",
    "        #restworkflowcontext.outPlotly(9, title=\"MEAN OF\", text=example_plotly )\n",
    "        #fig = go.Figure(data=[go.Bar(x=summary_df[col], y=summary_df[\"TARGET_MEAN\"])])\n",
    "        fig = go.Figure(data=[go.Bar(x=summary_df[col], y=summary_df[\"TARGET_MEAN\"], marker_color='skyblue')])\n",
    "        fig.update_layout(\n",
    "            #title=f\"{target} mean for {col}\",\n",
    "            xaxis_title=col,\n",
    "            yaxis_title=target\n",
    "        )\n",
    "\n",
    "        # Display the chart (replace with your output method)\n",
    "        fig_html = plotly.offline.plot(fig, output_type='div', include_plotlyjs=False)\n",
    "        restworkflowcontext.outPlotly(9, title= f\"{target.upper()} MEAN FOR {col.upper()}\", text=fig_html )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64252588-4c7e-4a7f-a0f2-ad458685e119",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.016947,
     "end_time": "2024-08-01T22:26:43.743112",
     "exception": false,
     "start_time": "2024-08-01T22:26:43.726165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "__Loading the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba3ad0a-d454-4bd1-8fb4-ad3922a0f8e3",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:43.784369Z",
     "iopub.status.busy": "2024-08-01T22:26:43.783729Z",
     "iopub.status.idle": "2024-08-01T22:26:44.835974Z",
     "shell.execute_reply": "2024-08-01T22:26:44.834603Z"
    },
    "papermill": {
     "duration": 1.074814,
     "end_time": "2024-08-01T22:26:44.838861",
     "exception": false,
     "start_time": "2024-08-01T22:26:43.764047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('/dbfs/FileStore/Demand-Forecasting/Input/demand-train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('/dbfs/FileStore/Demand-Forecasting/Input/demand-test.csv', parse_dates=['date'])\n",
    "\n",
    "#sample_sub = pd.read_csv('/dbfs/FileStore/Demand-Forecasting/Input/demand_forecasting.csv')\n",
    "\n",
    "df = pd.concat([train, test], sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e77452bb-89a1-4938-af5e-1fedf9aa9b58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### Time series decomposition\n",
    "-  Time series data is a sequence of data points indexed in time order, typically at uniform intervals, used to track changes over time and analyze trends, patterns, and seasonal variations.\n",
    "- A time series is stationary when its statistical characteristics, such as mean, variance and covariance don't change over time.\n",
    "- Time series decomposition: Analyze time series data by breaking it down into components to understand the underlying patterns, trends and irregularities within the data.\n",
    "- Trend, seasonal, cyclical and residual components.\n",
    "- Trend Component: Underlying long-term progression or direction of the time series. Shows wheter the data is increasing, decreasing or remaining relatively constant over time.\n",
    "- Seasonal Component: Regular, periodic fluctuations or patterns that occurs at specific intervals within the time series (annually, quarterly, monthly, and so on).\n",
    "- Cyclical Component: Fluctuations in the time series that are not of a fixed period. Typically associated with business/economic cycles.\n",
    "- Residual Component: Random fluctuations or irregularities that cannot be attributed to the trend, seasonal or cyclical patterns. Unexplained variability in the time series.\n",
    "- In order to perform time series decomposition, I will use the statsmodels package, applying seasonal decomposition using moving averages.\n",
    "- Moving Average: A moving average is a method that smooths data by creating averages from subsets of consecutive data points, providing a clearer picture of trends and patterns while reducing noise and short-term fluctuations.\n",
    "- Approaches used to decompose a time series: Additive Model, Multiplicative Model.\n",
    "- Additive Model: Time Series = Trend + Seasonal + Cyclical + Residual. The relation between the components is linear, constant variance over time.\n",
    "- Multiplicative Model: Time Series = Trend * Seasonal * Cyclical * Residual. The relation between the components is non-linear, variance is not constant over time, changing with the level of the series (average value around which the data fluctuates)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13459770-6e15-4ff2-a0b3-623b9bfde682",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Building Modular Functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83943d03-7c77-4127-968a-ba3b09508acc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_analysis(dataframe, options):\n",
    "    global should_continue_execution \n",
    "    # Retrieve widget values\n",
    "    rb_summary = dbutils.widgets.get(\"rb_summary\")\n",
    "    rb_detail = dbutils.widgets.get(\"rb_detail\")\n",
    "\n",
    "    # Ensure rb_detail is a string for consistent comparison\n",
    "    if isinstance(rb_detail, int):\n",
    "        rb_detail = str(rb_detail)\n",
    "\n",
    "    # Debug print statement\n",
    "    print(f\"Retrieved rb_summary: {rb_summary} and rb_detail: {rb_detail}\")\n",
    "\n",
    "    # Check if both rb_summary and rb_detail are set to 'Y' and '1' respectively\n",
    "    if rb_summary == 'Y' and rb_detail == '1':\n",
    "        check_df(dataframe)\n",
    "        target_summary_with_cat(\n",
    "            dataframe,\n",
    "            options['target'],\n",
    "            options['categorical_col']\n",
    "        )\n",
    "        should_continue_execution = False\n",
    "        return  # Stop further execution\n",
    "\n",
    "    # Check if only rb_summary is set to 'Y'\n",
    "    if rb_summary == 'Y':\n",
    "        check_df(dataframe)\n",
    "        should_continue_execution = False\n",
    "        return  # Stop further execution\n",
    "\n",
    "    # Check if only rb_detail is set to '1'\n",
    "    if rb_detail == '1':\n",
    "        target_summary_with_cat(\n",
    "            dataframe,\n",
    "            options['target'],\n",
    "            options['categorical_col']\n",
    "        )\n",
    "        should_continue_execution = False\n",
    "        return  # Stop further execution\n",
    "\n",
    "    if rb_detail == '2' and rb_summary == 'N':\n",
    "        should_continue_execution = True  # Ensure execution continues to the next cell\n",
    "        print(\"Skipping this cell based on rb_detail and rb_summary values.\")\n",
    "        return  # Exit the function, skipping the rest of the cell\n",
    "\n",
    "\n",
    "\n",
    "# Example usage of the function\n",
    "dataframe = df\n",
    "options = {\n",
    "    'target': 'sales',           # Replace 'sales' with the actual target column name in your DataFrame\n",
    "    'categorical_col': ['store', 'item']  # Replace 'store' and 'item' with the actual categorical column names in your DataFrame\n",
    "}\n",
    "\n",
    "# Call the run_analysis function\n",
    "run_analysis(dataframe, options)\n",
    "\n",
    "if not should_continue_execution:\n",
    "    message=\"100\"\n",
    "    restworkflowcontext.outputProgress(9, title=\"Progress\", progress=message)\n",
    "\n",
    "    message = \"Job Execution Completed.\"\n",
    "    restworkflowcontext.outSuccess(9, title=\"Success\", text=message)    \n",
    "    dbutils.notebook.exit(\"Execution stopped by run_analysis function.\")\n",
    "else:\n",
    "    print(f\"First  values: rb_detail={rb_detail}, rb_summary={rb_summary}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e9ae0f-3040-4167-a3f0-533680e9dd25",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:46.566698Z",
     "iopub.status.busy": "2024-08-01T22:26:46.566203Z",
     "iopub.status.idle": "2024-08-01T22:26:46.731776Z",
     "shell.execute_reply": "2024-08-01T22:26:46.730255Z"
    },
    "papermill": {
     "duration": 0.185447,
     "end_time": "2024-08-01T22:26:46.734781",
     "exception": false,
     "start_time": "2024-08-01T22:26:46.549334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Skipping this cell based on rb_detail and rb_summary values.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Skipping this cell based on rb_detail and rb_summary values.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to provide a more comprehensive understanding of sales performance.\n",
    "#Total Sales: See which store-item combinations generate the highest overall revenue.\n",
    "#Average Sales: Understand typical sales performance for each combination.\n",
    "#Median Sales: Get a sense of the \"typical\" sale amount, less influenced by outliers.\n",
    "\n",
    "#Example Business Questions that can be answered:\n",
    "  #Which store-item pair has the highest total sales value?\n",
    "  #Which store-item pair has the highest average sales value?\n",
    "  #Which store-item pair has the most consistent sales values (i.e., lowest standard deviation)?\n",
    "\n",
    "\n",
    "\n",
    "def generate_detailed_sales_summary(df):\n",
    "    summary_df = df.groupby([\"store\", \"item\"]).agg({\"sales\": [\"sum\", \"mean\", \"median\", \"std\"]})\n",
    "\n",
    "    # Find the store-item pair with the highest total sales value\n",
    "    highest_total_sales = summary_df['sales']['sum'].nlargest(1)\n",
    "\n",
    "    # Find the store-item pair with the highest average sales value\n",
    "    highest_average_sales = summary_df['sales']['mean'].nlargest(1)\n",
    "\n",
    "    # Find the store-item pair with the most consistent sales values (i.e., lowest standard deviation)\n",
    "    most_consistent_sales = summary_df['sales']['std'].nsmallest(1)\n",
    "\n",
    "\n",
    "    print(f\"Aggregates: highest_total_sales={highest_total_sales}, highest_average_sales={highest_average_sales}\") \n",
    "\n",
    "    # Create HTML string with styled output\n",
    "    html_output = f\"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif; background-color: #f5f5f5; padding: 20px; border-radius: 5px;\">\n",
    "        <h2 style=\"color: #333; font-size: 24px; margin-bottom: 20px;\">Sales Analysis For Store-Item pair</h2>\n",
    "        <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "            <thead>\n",
    "                <tr style=\"background-color: #0c9a86; color: white;\">\n",
    "                    <th style=\"padding: 10px; text-align: left;\">Metric</th>\n",
    "                    <th style=\"padding: 10px; text-align: left;\">Store</th>\n",
    "                    <th style=\"padding: 10px; text-align: left;\">Item</th>\n",
    "                    <th style=\"padding: 10px; text-align: left;\">Value</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "                <tr style=\"background-color: #f2f2f2;\">\n",
    "                    <td style=\"padding: 8px; text-align: left;\">Highest Total Sales</td>\n",
    "                    {''.join([f'<td style=\"padding: 8px; text-align: left;\">{int(v) if i in [1, 2] else v}</td>' for i, v in enumerate(highest_total_sales.reset_index().iloc[0].values)])}\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"padding: 8px; text-align: left;\">Highest Average Sales</td>\n",
    "                    {''.join([f'<td style=\"padding: 8px; text-align: left;\">{int(v) if i in [1, 2] else v}</td>' for i, v in enumerate(highest_average_sales.reset_index().iloc[0].values)])}\n",
    "                </tr>\n",
    "                <tr style=\"background-color: #f2f2f2;\">\n",
    "                    <td style=\"padding: 8px; text-align: left;\">Most Consistent Sales</td>\n",
    "                    {''.join([f'<td style=\"padding: 8px; text-align: left;\">{int(v) if i in [1, 2] else v}</td>' for i, v in enumerate(most_consistent_sales.reset_index().iloc[0].values)])}\n",
    "                </tr>\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    #print(html_output)\n",
    "    restworkflowcontext.outHTML(16, title=\"Inital Insights\", text=html_output)\n",
    "\n",
    "    should_continue_execution = False\n",
    "    return  # Stop further execution\n",
    "\n",
    "if rb_detail  == '2':\n",
    "    # Call the function\n",
    "    generate_detailed_sales_summary(df)\n",
    "    should_continue_execution = False\n",
    "    message=\"100\"\n",
    "    restworkflowcontext.outputProgress(9, title=\"Progress\", progress=message)\n",
    "    message = \"Job Execution Completed.\"\n",
    "    restworkflowcontext.outSuccess(9, title=\"Success\", text=message)    \n",
    "    dbutils.notebook.exit(\"Execution stopped by generate_detailed_sales_summary function.\")    \n",
    "  \n",
    "elif rb_detail == '3' and rb_summary == 'N':\n",
    "    should_continue_execution = True  # Ensure execution continues to the next cell\n",
    "    print(\"Skipping this cell based on rb_detail and rb_summary values.\")\n",
    "  \n",
    "else:\n",
    "    # Exit the notebook if bt_insights is not 'Y'\n",
    "    message=\"100\"\n",
    "    restworkflowcontext.outputProgress(9, title=\"Progress\", progress=message)\n",
    "    message = \"Job Execution Completed.\"\n",
    "    restworkflowcontext.outSuccess(9, title=\"Success\", text=message)    \n",
    "    dbutils.notebook.exit(\"Execution stopped by generate_detailed_sales_summary function.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7a17ea8-c22c-4191-becf-180248e95f8f",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.017834,
     "end_time": "2024-08-01T22:26:46.768390",
     "exception": false,
     "start_time": "2024-08-01T22:26:46.750556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2) FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaeb659b-cc4c-414c-96ee-89793f0e91b7",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.020291,
     "end_time": "2024-08-01T22:26:46.808461",
     "exception": false,
     "start_time": "2024-08-01T22:26:46.788170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## a) Date Features\n",
    "Since it will be used with tree-based methods, we created new features based on the date variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ebed2f0-fe39-4666-95d2-ad037cb9ffb0",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:46.843711Z",
     "iopub.status.busy": "2024-08-01T22:26:46.842566Z",
     "iopub.status.idle": "2024-08-01T22:26:47.122974Z",
     "shell.execute_reply": "2024-08-01T22:26:47.121674Z"
    },
    "papermill": {
     "duration": 0.3023,
     "end_time": "2024-08-01T22:26:47.126198",
     "exception": false,
     "start_time": "2024-08-01T22:26:46.823898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_date_features(df):\n",
    "    df['month'] = df.date.dt.month\n",
    "    df['day_of_month'] = df.date.dt.day\n",
    "    df['day_of_year'] = df.date.dt.dayofyear\n",
    "    df['day_of_week'] = df.date.dt.dayofweek\n",
    "    df['year'] = df.date.dt.year\n",
    "    df[\"is_wknd\"] = df.date.dt.weekday // 4\n",
    "    df['is_month_start'] = df.date.dt.is_month_start.astype(int)\n",
    "    df['is_month_end'] = df.date.dt.is_month_end.astype(int)\n",
    "    return df\n",
    "\n",
    "#df = create_date_features(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55370453-1769-4b65-a79a-ed40951e3feb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Visualizes average sales data at different aggregation levels with optional top N filtering.#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd2a68d-ecd1-4b2d-a4e4-6e8c12b2a913",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:47.161204Z",
     "iopub.status.busy": "2024-08-01T22:26:47.159810Z",
     "iopub.status.idle": "2024-08-01T22:26:47.273699Z",
     "shell.execute_reply": "2024-08-01T22:26:47.272328Z"
    },
    "papermill": {
     "duration": 0.134524,
     "end_time": "2024-08-01T22:26:47.276452",
     "exception": false,
     "start_time": "2024-08-01T22:26:47.141928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Average sales for each group.\n",
    "#df.groupby([\"store\", \"item\", \"month\"])[\"sales\"].mean().head(36)\n",
    "\n",
    "def plot_sales(df, plot_type=\"bar\", agg_level=\"month\", top_n=None):\n",
    "    \"\"\"\n",
    "    Plots average sales data, optionally showing the top N combinations.\n",
    "    \"\"\"\n",
    "    # Group by the specified level\n",
    "    if agg_level == \"month\":\n",
    "        sales_df = df.groupby(\"month\")[\"sales\"].mean().reset_index()\n",
    "        xlabel = \"Month\"\n",
    "    elif agg_level == \"store\":\n",
    "        sales_df = df.groupby(\"store\")[\"sales\"].mean().reset_index()\n",
    "        xlabel = \"Store\"\n",
    "    elif agg_level == \"item\":\n",
    "        sales_df = df.groupby(\"item\")[\"sales\"].mean().reset_index()\n",
    "        xlabel = \"Item\"\n",
    "    elif agg_level == \"store-item\":\n",
    "        sales_df = df.groupby([\"store\", \"item\"])[\"sales\"].mean().reset_index()\n",
    "        sales_df['store-item'] = sales_df['store'].astype(str) + '-' + sales_df['item'].astype(str)\n",
    "        xlabel = \"Store-Item Pair\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid aggregation level. Choose from: 'month', 'store', 'item', 'store-item'\")\n",
    "\n",
    "     # Filter out the aggregation levels with no sales\n",
    "    sales_df = sales_df[sales_df[\"sales\"] > 0]\n",
    "    # Sort the data by sales in descending order and select the top n combinations\n",
    "    if sales_df.shape[0] < top_n:\n",
    "        top_n = sales_df.shape[0]\n",
    "    sales_df = sales_df.sort_values(by=\"sales\", ascending=False).head(top_n)    \n",
    "\n",
    "    # Select top N combinations if top_n is specified\n",
    "    #if top_n is not None:\n",
    "    #    sales_df = sales_df.sort_values(by=\"sales\", ascending=False).head(top_n)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    if plot_type == \"bar\":\n",
    "        if agg_level == \"store-item\":\n",
    "            plt.bar(sales_df['store-item'], sales_df[\"sales\"])\n",
    "        else:\n",
    "            plt.bar(sales_df[agg_level], sales_df[\"sales\"])\n",
    "    elif plot_type == \"line\":\n",
    "        if agg_level == \"store-item\":\n",
    "            plt.plot(sales_df['store-item'], sales_df[\"sales\"])\n",
    "        else:\n",
    "            plt.plot(sales_df[agg_level], sales_df[\"sales\"])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid plot type. Choose from: 'bar', 'line'\")\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Average Sales\")\n",
    "    plt.title(f\"Average Sales by {xlabel.title()} (Top {top_n})\" if top_n else f\"Average Sales by {xlabel.title()}\")\n",
    "    plt.xticks(rotation=90 if agg_level == \"store-item\" else 0) \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#plot_sales(df, plot_type=\"bar\", agg_level=\"month\", top_n=5) # Show top 5 store-item combo\n",
    "#plot_sales(df, plot_type=\"bar\", agg_level=\"store\", top_n=5) # Show top 5 store-item combo\n",
    "#plot_sales(df, plot_type=\"bar\", agg_level=\"item\", top_n=5) # Show top 5 store-item combo\n",
    "#plot_sales(df, plot_type=\"bar\", agg_level=\"store-item\", top_n=5) # Show top 5 store-item combo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f21321ee-41be-4d40-acc7-39a63f1bed6e",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.015058,
     "end_time": "2024-08-01T22:26:47.339356",
     "exception": false,
     "start_time": "2024-08-01T22:26:47.324298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## b) Random Noise\n",
    "\n",
    "Random noise should be added to evaluate the overall performance of the model and to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddf80b8c-84e9-4642-93b6-4bb7ea77b1c2",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:47.373310Z",
     "iopub.status.busy": "2024-08-01T22:26:47.372521Z",
     "iopub.status.idle": "2024-08-01T22:26:47.379527Z",
     "shell.execute_reply": "2024-08-01T22:26:47.378238Z"
    },
    "papermill": {
     "duration": 0.027659,
     "end_time": "2024-08-01T22:26:47.382650",
     "exception": false,
     "start_time": "2024-08-01T22:26:47.354991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "def random_noise(dataframe):\n",
    "    return np.random.normal(scale=1.6, size=(len(dataframe),))\n",
    "'''\n",
    "def random_noise(dataframe, feature_flags):\n",
    "    return np.random.normal(scale=1.6, size=(len(dataframe),)) if feature_flags['random_noise'] else np.zeros(len(dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47a17401-597b-4652-8cfd-fe637c9dd257",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.0156,
     "end_time": "2024-08-01T22:26:47.683144",
     "exception": false,
     "start_time": "2024-08-01T22:26:47.667544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## c) Lag/Shifted Features\n",
    "\n",
    "The purpose of lag features is to use past data points to predict future values. They help the model learn patterns and dependencies over time, improving the accuracy of forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6dd4be5-48bd-4304-8175-bdd7bbfd9457",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:47.717257Z",
     "iopub.status.busy": "2024-08-01T22:26:47.716807Z",
     "iopub.status.idle": "2024-08-01T22:26:50.059547Z",
     "shell.execute_reply": "2024-08-01T22:26:50.058225Z"
    },
    "papermill": {
     "duration": 2.3626,
     "end_time": "2024-08-01T22:26:50.062497",
     "exception": false,
     "start_time": "2024-08-01T22:26:47.699897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[13]: &#39;\\ndef lag_features(dataframe, lags):\\n    for lag in lags:\\n        dataframe[\\&#39;sales_lag_\\&#39; + str(lag)] = dataframe.groupby([&#34;store&#34;, &#34;item&#34;])[\\&#39;sales\\&#39;].transform(\\n            lambda x: x.shift(lag)) + random_noise(dataframe)\\n    return dataframe\\ndf = lag_features(df, [91, 98, 105, 112, 119, 126, 182, 364, 546, 728])\\n&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[13]: &#39;\\ndef lag_features(dataframe, lags):\\n    for lag in lags:\\n        dataframe[\\&#39;sales_lag_\\&#39; + str(lag)] = dataframe.groupby([&#34;store&#34;, &#34;item&#34;])[\\&#39;sales\\&#39;].transform(\\n            lambda x: x.shift(lag)) + random_noise(dataframe)\\n    return dataframe\\ndf = lag_features(df, [91, 98, 105, 112, 119, 126, 182, 364, 546, 728])\\n&#39;</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lag_features(dataframe, lags, feature_flags):\n",
    "    for lag in lags:\n",
    "        dataframe[f'sales_lag_{lag}'] = dataframe.groupby([\"store\", \"item\"])['sales'].transform(\n",
    "            lambda x: x.shift(lag)) + random_noise(dataframe, feature_flags)\n",
    "    return dataframe\n",
    "\n",
    "'''\n",
    "def lag_features(dataframe, lags):\n",
    "    for lag in lags:\n",
    "        dataframe['sales_lag_' + str(lag)] = dataframe.groupby([\"store\", \"item\"])['sales'].transform(\n",
    "            lambda x: x.shift(lag)) + random_noise(dataframe)\n",
    "    return dataframe\n",
    "df = lag_features(df, [91, 98, 105, 112, 119, 126, 182, 364, 546, 728])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4ba9677-9387-4dd6-9303-2d87763557c9",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.017165,
     "end_time": "2024-08-01T22:26:50.096206",
     "exception": false,
     "start_time": "2024-08-01T22:26:50.079041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## d) Rolling Mean Features\n",
    "Rolling mean features help to smooth out short-term fluctuations in time series data, making it easier to identify long-term trends and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dba69064-8d8e-4878-8782-d0bbcb3479cd",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:50.128601Z",
     "iopub.status.busy": "2024-08-01T22:26:50.128170Z",
     "iopub.status.idle": "2024-08-01T22:26:52.766324Z",
     "shell.execute_reply": "2024-08-01T22:26:52.764562Z"
    },
    "papermill": {
     "duration": 2.657877,
     "end_time": "2024-08-01T22:26:52.769454",
     "exception": false,
     "start_time": "2024-08-01T22:26:50.111577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[14]: &#39;\\ndef roll_mean_features(dataframe, windows):\\n    for window in windows:\\n        dataframe[\\&#39;sales_roll_mean_\\&#39; + str(window)] = dataframe.groupby([&#34;store&#34;, &#34;item&#34;])[\\&#39;sales\\&#39;].                                                           transform(\\n            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=&#34;triang&#34;).mean()) + random_noise(\\n            dataframe)\\n    return dataframe\\n&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[14]: &#39;\\ndef roll_mean_features(dataframe, windows):\\n    for window in windows:\\n        dataframe[\\&#39;sales_roll_mean_\\&#39; + str(window)] = dataframe.groupby([&#34;store&#34;, &#34;item&#34;])[\\&#39;sales\\&#39;].                                                           transform(\\n            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=&#34;triang&#34;).mean()) + random_noise(\\n            dataframe)\\n    return dataframe\\n&#39;</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def roll_mean_features(dataframe, windows, feature_flags):\n",
    "    for window in windows:\n",
    "        dataframe[f'sales_roll_mean_{window}'] = dataframe.groupby([\"store\", \"item\"])['sales']. \\\n",
    "                                                          transform(\n",
    "            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=\"triang\").mean()) + random_noise(dataframe, feature_flags)\n",
    "    return dataframe\n",
    "\n",
    "'''\n",
    "def roll_mean_features(dataframe, windows):\n",
    "    for window in windows:\n",
    "        dataframe['sales_roll_mean_' + str(window)] = dataframe.groupby([\"store\", \"item\"])['sales']. \\\n",
    "                                                          transform(\n",
    "            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=\"triang\").mean()) + random_noise(\n",
    "            dataframe)\n",
    "    return dataframe\n",
    "'''\n",
    "\n",
    "#df = roll_mean_features(df, [365, 546])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e02eb1df-33c4-4d36-b3ec-de17c7e36683",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.015612,
     "end_time": "2024-08-01T22:26:52.799973",
     "exception": false,
     "start_time": "2024-08-01T22:26:52.784361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## e) Exponentially Weighted Mean Features\n",
    "* __EWMA (Exponential Weighted Moving Average):__ Computes the weighted moving average of the data, where more recent data points receive higher weights.\n",
    "* __Lag Features:__ Use past data to calculate the EWMA of historical values, helping to understand the dynamics of the data over time.\n",
    "* __Alpha Parameter:__ Determines the weight given to past periods. Higher alpha values place more emphasis on recent data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0204f274-dd28-46e5-891c-96cff3e42323",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:26:52.834895Z",
     "iopub.status.busy": "2024-08-01T22:26:52.834456Z",
     "iopub.status.idle": "2024-08-01T22:27:06.910922Z",
     "shell.execute_reply": "2024-08-01T22:27:06.909433Z"
    },
    "papermill": {
     "duration": 14.096699,
     "end_time": "2024-08-01T22:27:06.914363",
     "exception": false,
     "start_time": "2024-08-01T22:26:52.817664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def ewm_features(dataframe, alphas, lags):\n",
    "    for alpha in alphas:\n",
    "        for lag in lags:\n",
    "            dataframe[f'sales_ewm_alpha_{alpha}_lag_{lag}'] = \\\n",
    "                dataframe.groupby([\"store\", \"item\"])['sales'].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n",
    "    return dataframe\n",
    "\n",
    "'''\n",
    "def ewm_features(dataframe, alphas, lags):\n",
    "    for alpha in alphas:\n",
    "        for lag in lags:\n",
    "            dataframe['sales_ewm_alpha_' + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)] = \\\n",
    "                dataframe.groupby([\"store\", \"item\"])['sales'].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n",
    "    return dataframe\n",
    "'''\n",
    "alphas = [0.95, 0.9, 0.8, 0.7, 0.5]\n",
    "lags = [91, 98, 105, 112, 180, 270, 365, 546, 728]\n",
    "\n",
    "#df = ewm_features(df, alphas, lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b41e8ffa-22f3-47a4-a498-fd0ad3c6b5cf",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.014835,
     "end_time": "2024-08-01T22:27:06.946059",
     "exception": false,
     "start_time": "2024-08-01T22:27:06.931224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## f) One-Hot Encoding\n",
    "We performed one-hot encoding because, as observed in the data analysis, the sales amounts for each store and item vary. To help our model understand this better, we used one-hot encoding with get_dummies.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28140306-4754-4893-ba35-8aa854f70dee",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:27:06.978601Z",
     "iopub.status.busy": "2024-08-01T22:27:06.978181Z",
     "iopub.status.idle": "2024-08-01T22:27:08.255732Z",
     "shell.execute_reply": "2024-08-01T22:27:08.254437Z"
    },
    "papermill": {
     "duration": 1.298155,
     "end_time": "2024-08-01T22:27:08.259385",
     "exception": false,
     "start_time": "2024-08-01T22:27:06.961230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df = pd.get_dummies(df, columns=['store', 'item', 'day_of_week', 'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec677cf0-bcac-4670-beda-6403c2850e9e",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.01482,
     "end_time": "2024-08-01T22:27:08.290483",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.275663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## g) Converting sales to log(1+sales)\n",
    "We applied a logarithmic transformation using log(1+sales) to make the model run more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "316a408c-625a-43f5-9be2-53cf69cb7c71",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:27:08.324607Z",
     "iopub.status.busy": "2024-08-01T22:27:08.324204Z",
     "iopub.status.idle": "2024-08-01T22:27:08.349424Z",
     "shell.execute_reply": "2024-08-01T22:27:08.348207Z"
    },
    "papermill": {
     "duration": 0.044886,
     "end_time": "2024-08-01T22:27:08.352244",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.307358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df['sales'] = np.log1p(df[\"sales\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77627a79-20d1-4f1d-9c45-32c97aee6de9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[18]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[18]: </div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958000 rows  5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>store</th>\n      <th>item</th>\n      <th>sales</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013-01-01</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2013-01-02</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2013-01-03</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013-01-04</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013-01-05</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44995</th>\n      <td>2018-03-27</td>\n      <td>10</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>44995.0</td>\n    </tr>\n    <tr>\n      <th>44996</th>\n      <td>2018-03-28</td>\n      <td>10</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>44996.0</td>\n    </tr>\n    <tr>\n      <th>44997</th>\n      <td>2018-03-29</td>\n      <td>10</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>44997.0</td>\n    </tr>\n    <tr>\n      <th>44998</th>\n      <td>2018-03-30</td>\n      <td>10</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>44998.0</td>\n    </tr>\n    <tr>\n      <th>44999</th>\n      <td>2018-03-31</td>\n      <td>10</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>44999.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>958000 rows  5 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b300a8a-43ec-4fcd-9a5e-f36d5ea13760",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Feature Engineering Modular Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9344f597-75bb-4a3c-957c-019e11543e81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(\"rb_detail\", rb_features)  \n",
    "\n",
    "\n",
    "flag_mapping = {\n",
    "    'RF': 'random_noise',\n",
    "    'LF': 'lag_features',\n",
    "    'RMF': 'rolling_mean_features',\n",
    "    'EF': 'ewm_features',\n",
    "    'OHE': 'one_hot_encoding',\n",
    "    'LT': 'log_transform'\n",
    "}\n",
    "\n",
    "# Split rb_features by '|' and clean the flags\n",
    "selected_flags = [flag_mapping.get(flag.strip().upper()) for flag in rb_features.split('|') if flag.strip().upper() in flag_mapping]\n",
    "\n",
    "# Set the feature_flags based on the selected_flags\n",
    "feature_flags = {flag: True for flag in selected_flags}\n",
    "for flag in flag_mapping.values():\n",
    "    if flag not in selected_flags:\n",
    "        feature_flags[flag] = False\n",
    "\n",
    "#print(\"Before\" , df.columns)\n",
    "\n",
    "\n",
    "def feature_engineering(df, feature_flags):\n",
    "    if 'date' not in df.columns:\n",
    "        raise ValueError(\"Date column not found in DataFrame\")\n",
    "\n",
    "    df = create_date_features(df)\n",
    "\n",
    "    original_columns = df.columns\n",
    "\n",
    "    if feature_flags['one_hot_encoding']:\n",
    "        columns_to_encode = ['store', 'item', 'day_of_week', 'month']\n",
    "        columns_to_encode = [col for col in columns_to_encode if col in df.columns]\n",
    "        df = pd.get_dummies(df, columns=columns_to_encode, prefix_sep='_')\n",
    "\n",
    "    if 'store' not in df.columns or 'item' not in df.columns:\n",
    "        if 'store' not in df.columns:\n",
    "            store_columns = [col for col in df.columns if col.startswith('store_')]\n",
    "            if store_columns:\n",
    "                df['store'] = df[store_columns].idxmax(axis=1).str.split('_').str[1]\n",
    "        if 'item' not in df.columns:\n",
    "            item_columns = [col for col in df.columns if col.startswith('item_')]\n",
    "            if item_columns:\n",
    "                df['item'] = df[item_columns].idxmax(axis=1).str.split('_').str[1]\n",
    "\n",
    "    if feature_flags['lag_features']:\n",
    "        df = lag_features(df, [91, 98, 105, 112, 119, 126, 182, 364, 546, 728], feature_flags)\n",
    "\n",
    "    if feature_flags['rolling_mean_features']:\n",
    "        df = roll_mean_features(df, [365, 546], feature_flags)\n",
    "\n",
    "    if feature_flags['ewm_features']:\n",
    "        alphas = [0.95, 0.9, 0.8, 0.7, 0.5]\n",
    "        lags = [91, 98, 105, 112, 180, 270, 365, 546, 728]\n",
    "        df = ewm_features(df, alphas, lags)\n",
    "\n",
    "    if feature_flags['log_transform']:\n",
    "        df['sales'] = np.log1p(df[\"sales\"].values)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming `df` is your DataFrame before feature engineering\n",
    "if rb_detail == '3':\n",
    "    # Call the function\n",
    "    #df, html_output = feature_engineering(df, feature_flags)\n",
    "    df = feature_engineering(df, feature_flags)\n",
    "    \n",
    "    #df.to_csv(\"/dbfs/FileStore/Demand-Forecasting/features-Dataset/demand_forecasting_features_dataset.csv\", index=False)\n",
    "    df.to_csv(\"/dbfs/FileStore/Demand-Forecasting/features-Dataset/demand_forecasting_features_dataset.csv\", index=False, mode='w')\n",
    "\n",
    "    #print(\"-----------\")\n",
    "    df_tail = df.tail(10)\n",
    "    df_tail\n",
    "    #print(\"-----------\")\n",
    "    # Get the column names\n",
    "    #column_names = df.columns\n",
    "\n",
    "    # Get the last 5 rows for each column\n",
    "    #df_head = df.tail(5).reset_index(drop=True)\n",
    "\n",
    "    # Align the column names with df_head\n",
    "    #common_columns = column_names.intersection(df_head.columns)\n",
    "    #df_head = df_head.reindex(columns=common_columns)\n",
    "\n",
    "    # Create a MultiIndex DataFrame with common column names as the first level and column values as the second level\n",
    "    #summary_df = pd.DataFrame({(col, ''): df_head[col] for col in common_columns})\n",
    "   # summary_html = df_tail.to_html(index=False, border=0, classes='table table-striped')\n",
    "    #restworkflowcontext.outHTML(9, title=\"Feature Engineered Dataset\", text=summary_html)\n",
    "\n",
    "    # Define the base download URL\n",
    "    csv_file_path = f\"/dbfs/FileStore/Demand-Forecasting/features-Dataset/demand_forecasting_features_dataset.csv\"\n",
    "\n",
    "    base_download_url = \"https://sparkflows.kimberly-clark.com/api/v1/dbfs/files/download\"\n",
    "    csv_file_path_mod = f\"/FileStore/Demand-Forecasting/features-Dataset/demand_forecasting_features_dataset.csv\"\n",
    "    file_size_bytes = 3366 #kept aribtrary small for demo purpose\n",
    "\n",
    "    # Construct the full download URL\n",
    "    download_link = f\"{base_download_url}?connectionId=363&fileSize={file_size_bytes}&filePath={csv_file_path_mod}\"\n",
    "    restworkflowcontext.outHTML(13, title = 'Feature Engineered Dataset', text =f\"<a href='{download_link}' download style='font-size: 18px; font-weight: bold; color: #FF0000;cursor: pointer;''>Feature Engineered Dataset</a>\")   \n",
    "\n",
    "\n",
    "    # Convert DataFrame to HTML\n",
    "    #summary_html = summary_df.to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "\n",
    "    '''\n",
    "    # Get the first five rows\n",
    "    df_head = df.head(5)\n",
    "    # Reset the index of both DataFrames\n",
    "    column_names = pd.DataFrame(column_names).reset_index(drop=True)\n",
    "\n",
    "    df_head = df_head.reset_index(drop=True)\n",
    "\n",
    "    # Combine column names and first five rows into a single DataFrame\n",
    "    summary_df = pd.concat([column_names, df_head], axis=1)\n",
    "    '''\n",
    "    # Convert DataFrame to HTML\n",
    "    #summary_html = summary_df.to_html(index=False, border=0, classes='table table-striped')\n",
    "\n",
    "    #restworkflowcontext.outHTML(9, title=\"Sample Featured Engineer Dataset\", text=summary_html)\n",
    "    message = \"100\"\n",
    "    #should_continue_execution = False \n",
    "    restworkflowcontext.outputProgress(9, title=\"Progress\", progress=message)\n",
    "    message = \"Job Execution Completed without Feature Engineering.\"\n",
    "    restworkflowcontext.outSuccess(9, title=\"Success\", text=message)    \n",
    "    #dbutils.notebook.exit(\"Execution stopped due to non-feature engineering case.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2cdddfb-eed6-4c34-a592-73f5b9a7c7e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "should_continue_execution = False \n",
    "dbutils.notebook.exit(\"Execution stopped due to non-feature engineering case.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bc37618-f28c-4044-bdad-9705e6006b9f",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:27:08.414769Z",
     "iopub.status.busy": "2024-08-01T22:27:08.414354Z",
     "iopub.status.idle": "2024-08-01T22:27:08.422669Z",
     "shell.execute_reply": "2024-08-01T22:27:08.421547Z"
    },
    "papermill": {
     "duration": 0.027068,
     "end_time": "2024-08-01T22:27:08.425023",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.397955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SMAPE: Symmetric mean absolute percentage error (adjusted MAPE)\n",
    "\n",
    "def smape(preds, target):\n",
    "    n = len(preds)\n",
    "    masked_arr = ~((preds == 0) & (target == 0))\n",
    "    preds, target = preds[masked_arr], target[masked_arr]\n",
    "    num = np.abs(preds - target)\n",
    "    denom = np.abs(preds) + np.abs(target)\n",
    "    smape_val = (200 * np.sum(num / denom)) / n\n",
    "    return smape_val\n",
    "\n",
    "\n",
    "def lgbm_smape(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    smape_val = smape(np.expm1(preds), np.expm1(labels))\n",
    "    return 'SMAPE', smape_val, False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76e9c280-fd42-4c45-9f1b-99dee04db339",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.015271,
     "end_time": "2024-08-01T22:27:08.455375",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.440104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ## b) Time-Based Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f61a47d-421b-40bc-af6d-89c3af3a27b6",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:27:08.488810Z",
     "iopub.status.busy": "2024-08-01T22:27:08.488363Z",
     "iopub.status.idle": "2024-08-01T22:27:08.498462Z",
     "shell.execute_reply": "2024-08-01T22:27:08.497005Z"
    },
    "papermill": {
     "duration": 0.030552,
     "end_time": "2024-08-01T22:27:08.501192",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.470640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.date.max(), test.date.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2960aac0-5533-45ae-8b2d-9d880752bccb",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.015349,
     "end_time": "2024-08-01T22:27:08.531994",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.516645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We selected the validation set within the range from January 1, 2017, to March 31, 2017, to best represent the time period we want to predict with our model, which covers from January 1, 2018, to March 31, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c7f03f9-5436-4fed-83dc-f9d062e969e4",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:27:08.564491Z",
     "iopub.status.busy": "2024-08-01T22:27:08.564065Z",
     "iopub.status.idle": "2024-08-01T22:27:08.908156Z",
     "shell.execute_reply": "2024-08-01T22:27:08.906873Z"
    },
    "papermill": {
     "duration": 0.36402,
     "end_time": "2024-08-01T22:27:08.911328",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.547308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "# Train set: Data up to the beginning of 2017 (end of 2016).\n",
    "train = df.loc[(df[\"date\"] < \"2017-01-01\"), :]\n",
    "\n",
    "# Validation set: The first 3 months of 2017.\n",
    "val = df.loc[(df[\"date\"] >= \"2017-01-01\") & (df[\"date\"] < \"2017-04-01\"), :]\n",
    "\n",
    "# Selecting features and target variables\n",
    "cols = [col for col in train.columns if col not in ['date', 'id', 'sales', 'year']]\n",
    "\n",
    "Y_train = train['sales']  # Target variable for the training set\n",
    "X_train = train[cols]     # Feature variables for the training set\n",
    "\n",
    "Y_val = val['sales']      # Target variable for the validation set\n",
    "X_val = val[cols]         # Feature variables for the validation set\n",
    "\n",
    "# Display the shapes of the target and feature variables for both training and validation sets\n",
    "Y_train.shape, X_train.shape, Y_val.shape, X_val.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20b212a5-49ae-44d6-a023-9c2622e2f8fc",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.016009,
     "end_time": "2024-08-01T22:27:08.942788",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.926779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## c) Time Series Model Using LightGBM\n",
    "\n",
    "First, hyperparameters were optimized using Random Search CV, followed by Grid Search CV to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7fc355b-133c-4192-9538-31e2af8b0e63",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:27:08.975500Z",
     "iopub.status.busy": "2024-08-01T22:27:08.975075Z",
     "iopub.status.idle": "2024-08-01T22:28:56.363278Z",
     "shell.execute_reply": "2024-08-01T22:28:56.362104Z"
    },
    "papermill": {
     "duration": 107.408082,
     "end_time": "2024-08-01T22:28:56.366202",
     "exception": false,
     "start_time": "2024-08-01T22:27:08.958120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "# LightGBM parameters\n",
    "lgb_params = {'num_leaves': 10,\n",
    "              'learning_rate': 0.02,\n",
    "              'feature_fraction': 0.8,\n",
    "              'max_depth': 5,\n",
    "              'verbose': 0,\n",
    "              'num_boost_round': 1000,\n",
    "              'early_stopping_rounds': 200,\n",
    "              'nthread': -1}\n",
    "\n",
    "lgbtrain = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\n",
    "\n",
    "lgbval = lgb.Dataset(data=X_val, label=Y_val, reference=lgbtrain, feature_name=cols)\n",
    "\n",
    "# Train the model\n",
    "model = lgb.train(\n",
    "    lgb_params, \n",
    "    lgbtrain,\n",
    "    valid_sets=[lgbtrain, lgbval],\n",
    "    callbacks=[lgb.early_stopping(lgb_params['early_stopping_rounds'])]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5683d315-ec66-4238-be4b-39c6dca7be14",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:28:56.468865Z",
     "iopub.status.busy": "2024-08-01T22:28:56.467826Z",
     "iopub.status.idle": "2024-08-01T22:28:57.336771Z",
     "shell.execute_reply": "2024-08-01T22:28:57.335486Z"
    },
    "papermill": {
     "duration": 0.888907,
     "end_time": "2024-08-01T22:28:57.339638",
     "exception": false,
     "start_time": "2024-08-01T22:28:56.450731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "y_pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "\n",
    "smape(np.expm1(y_pred_val), np.expm1(Y_val))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a8eedf4-d505-4f44-b510-a09160bfb788",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.015519,
     "end_time": "2024-08-01T22:28:57.371193",
     "exception": false,
     "start_time": "2024-08-01T22:28:57.355674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## d) Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "118ba204-cfa1-4bb6-94ca-7bba7d298821",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:28:57.406733Z",
     "iopub.status.busy": "2024-08-01T22:28:57.405667Z",
     "iopub.status.idle": "2024-08-01T22:28:58.137201Z",
     "shell.execute_reply": "2024-08-01T22:28:58.135963Z"
    },
    "papermill": {
     "duration": 0.753893,
     "end_time": "2024-08-01T22:28:58.142274",
     "exception": false,
     "start_time": "2024-08-01T22:28:57.388381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "def plot_lgb_importances(model, plot=False, num=10):\n",
    "    gain = model.feature_importance('gain')\n",
    "    feat_imp = pd.DataFrame({'feature': model.feature_name(),\n",
    "                             'split': model.feature_importance('split'),\n",
    "                             'gain': 100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.set(font_scale=1)\n",
    "        sns.barplot(x=\"gain\", y=\"feature\", data=feat_imp[0:25])\n",
    "        plt.title('Feature Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(feat_imp.head(num))\n",
    "    return feat_imp\n",
    "\n",
    "# Plot the top 200 feature importances and display the top 30 features\n",
    "plot_lgb_importances(model, num=200)\n",
    "plot_lgb_importances(model, num=30, plot=True)\n",
    "\n",
    "# Get the feature importances\n",
    "feat_imp = plot_lgb_importances(model, num=200)\n",
    "\n",
    "# Identify features with zero importance\n",
    "importance_zero = feat_imp[feat_imp[\"gain\"] == 0][\"feature\"].values\n",
    "\n",
    "# Filter out features with zero importance\n",
    "imp_feats = [col for col in cols if col not in importance_zero]\n",
    "len(imp_feats)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d46000d-b562-439e-8b39-9494b81c17b1",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.017578,
     "end_time": "2024-08-01T22:28:58.177792",
     "exception": false,
     "start_time": "2024-08-01T22:28:58.160214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When examining feature importance, it is evident that the features created during feature engineering have a significant impact on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd165509-2d9c-4b12-b14e-0f356e092ce3",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.01786,
     "end_time": "2024-08-01T22:28:58.213355",
     "exception": false,
     "start_time": "2024-08-01T22:28:58.195495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4) FINAL MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "140ad1cc-a8a9-4168-8a80-b1dfcb14b57b",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:28:58.252827Z",
     "iopub.status.busy": "2024-08-01T22:28:58.252380Z",
     "iopub.status.idle": "2024-08-01T22:31:06.948497Z",
     "shell.execute_reply": "2024-08-01T22:31:06.946999Z"
    },
    "papermill": {
     "duration": 128.719869,
     "end_time": "2024-08-01T22:31:06.951733",
     "exception": false,
     "start_time": "2024-08-01T22:28:58.231864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "train = df.loc[~df.sales.isna()]\n",
    "Y_train = train['sales']\n",
    "X_train = train[cols]\n",
    "\n",
    "\n",
    "test = df.loc[df.sales.isna()]\n",
    "X_test = test[cols]\n",
    "\n",
    "lgb_params = {'num_leaves': 10,\n",
    "              'learning_rate': 0.02,\n",
    "              'feature_fraction': 0.8,\n",
    "              'max_depth': 5,\n",
    "              'verbose': 0,\n",
    "              'nthread': -1,\n",
    "              \"num_boost_round\": model.best_iteration}\n",
    "\n",
    "lgbtrain_all = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\n",
    "\n",
    "final_model = lgb.train(lgb_params, lgbtrain_all, num_boost_round=model.best_iteration)\n",
    "\n",
    "\n",
    "\n",
    "test_preds = final_model.predict(X_test, num_iteration=model.best_iteration)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11453d41-8e96-4391-a102-a924ccb5ec13",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.01766,
     "end_time": "2024-08-01T22:31:06.987804",
     "exception": false,
     "start_time": "2024-08-01T22:31:06.970144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce6689e5-2127-4ec4-baa5-5eaaf9ceb20b",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-08-01T22:31:07.027852Z",
     "iopub.status.busy": "2024-08-01T22:31:07.027406Z",
     "iopub.status.idle": "2024-08-01T22:31:07.184799Z",
     "shell.execute_reply": "2024-08-01T22:31:07.183744Z"
    },
    "papermill": {
     "duration": 0.180538,
     "end_time": "2024-08-01T22:31:07.187632",
     "exception": false,
     "start_time": "2024-08-01T22:31:07.007094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "submission_df = test.loc[:, [\"id\", \"sales\"]]\n",
    "submission_df['sales'] = np.expm1(test_preds)\n",
    "\n",
    "submission_df['id'] = submission_df.id.astype(int)\n",
    "\n",
    "submission_df\n",
    "#submission_df.to_csv(\"submission_demand.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c346973-f4e3-4d2f-a2e2-c93f743aa268",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "message=\"100\"\n",
    "restworkflowcontext.outputProgress(9, title=\"Progress\", progress=message)\n",
    "\n",
    "message = \"Job Execution Completed.\"\n",
    "restworkflowcontext.outSuccess(9, title=\"Success\", text=message)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "mod-demand-forecasting",
   "widgets": {
    "job-id": {
     "currentValue": "100",
     "nuid": "7ab58334-a550-4b5d-b181-8664828bc9ec",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "100",
      "label": null,
      "name": "job-id",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "100",
      "label": null,
      "name": "job-id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "option": {
     "currentValue": "",
     "nuid": "95814bc5-beda-40b2-8449-0448dbae5d1d",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "option",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "postback-url": {
     "currentValue": "",
     "nuid": "e9230ecc-446e-4c7a-9423-c75b824d4088",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "postback-url",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "postback-url",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "rb_detail": {
     "currentValue": "1",
     "nuid": "0c36c277-d5d3-4d60-b52a-1c4d3af57a67",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "rb_detail",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "rb_detail",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "rb_detail_org": {
     "currentValue": "1",
     "nuid": "6bdcb47a-8bb9-4238-8128-456ca7fa2f8e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "rb_detail_org",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "rb_detail_org",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "rb_summary": {
     "currentValue": "Y",
     "nuid": "8ffca03c-1015-4b0b-b5cb-e682aa53a941",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "rb_summary",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "rb_summary",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868225,
     "sourceId": 9999,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 272.421777,
   "end_time": "2024-08-01T22:31:08.030688",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-01T22:26:35.608911",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
